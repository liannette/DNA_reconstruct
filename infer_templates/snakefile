"""
Right now the results are different every time the pipeline is run. 
This is because gargammel fragSim creates different DNA fragments each 
time, it is not possible to set a seed for this step. Therefore, when
publishing the results, the fragments should be made publicly available.

AdapterRemoval uses a seed when choosing between bases with equal Phred
scores when merging the reads. The other trimming methods don't specify
what happens in such a case.

TO DO
- add gzip
- delete unneccessary variables
- Check if the merged output file really contains only merged reads by
  comparing with leonardos files (header of the reads):
  bbmerge, adna-trim 

Unclear Phred Score offset of adna-trim, bbmerge
"""


### Set global variables


SEED = 2718

# fragment variables
#LENGTHS = list(range(1, 250+1)) + [1000]
#NUMFRAGS = 1000000
LENGTHS = [10, 20, 50, 100, 250, 1000] 
NUMFRAGS = 50



# Input genome and adapter sequences
IN_FILE = "/home/databases/genomes/Homo_sapiens/CHM13_T2T/CHM13_T2T.fa"
ADPT_FILE = "/home/projects/DNA_reconstruct/input_files/adapters.fa"
ADPT1 = "AGATCGGAAGAGCACACGTCTGAACTCCAGTCACCGATTCGATCTCGTATGCCGTCTTCTGCTTG"
ADPT2 = "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATTT"

# output directories
OUTDIR = "/net/node07/home/projects/DNA_reconstruct/infer_templates/output/"
OUTDIR_BEN = OUTDIR + "benchmarks/"
OUTDIR_SIM = OUTDIR + "simulations/"
OUTDIR_REC = OUTDIR + "reconstructions/"
OUTDIR_EVA = OUTDIR + "evaluation/"

# tools
FRAGSIM = "/home/ctools/gargammel/src/fragSim"
ADPTSIM = "/home/ctools/gargammel/src/adptSim"
ART = "/home/ctools/gargammel/art_src_MountRainier_Linux/art_illumina"
LEEHOM = "/home/ctools/leeHom-1.2.15/src/leeHom"
ADPTREM = "/home/ctools/adapterremoval-2.3.2/build/AdapterRemoval"
CLIPMERGE = "/home/ctools/ClipAndMerge-1.7.8/build/libs/ClipAndMerge-1.7.8.jar"
SEQTK = "/home/ctools/seqtk-1.3/seqtk"
ADNA = "/home/ctools/adna/adna-trim"
BBMERGE = "/home/ctools/bbmap_38_91/bbmerge.sh"
FASTP = "/home/ctools/fastp/fastp"
SEQPREP = "/home/ctools/SeqPrep-1.3.2/SeqPrep"

# evaluation script
EVAL_SCRIPT = "/home/projects/DNA_reconstruct/eval_infer_templates.py"

# conda environment
CONDA_ENV = "/net/node07/home/projects/DNA_reconstruct/conda_env.yaml"


### Run all


rule all:
    input:
        expand(
            OUTDIR_EVA + "leeHom/gen_n{n}_l{l}_lh.csv",
            n=NUMFRAGS,
            l=LENGTHS,
        ),
        expand(
            OUTDIR_EVA + "AdapterRemoval/gen_n{n}_l{l}_ar.csv",
            n=NUMFRAGS,
            l=LENGTHS,
        ),
        expand(
            OUTDIR_EVA + "ClipAndMerge/gen_n{n}_l{l}_cm.csv",
            n=NUMFRAGS,
            l=LENGTHS,
        ),
        expand(
            OUTDIR_EVA + "seqtk_adna_trim/gen_n{n}_l{l}_at.csv",
            n=NUMFRAGS,
            l=LENGTHS,
        ),
        expand(
            OUTDIR_EVA + "bbmerge/gen_n{n}_l{l}_bb.csv",
            n=NUMFRAGS,
            l=LENGTHS,
        ),
        expand(
            OUTDIR_EVA + "fastp/gen_n{n}_l{l}_fp.csv",
            n=NUMFRAGS,
            l=LENGTHS,
        ),
        expand(
            OUTDIR_EVA + "SeqPrep/gen_n{n}_l{l}_sp.csv",
            n=NUMFRAGS,
            l=LENGTHS,
        ),


### Simulation


rule simulate_fragments:
    """
    gargammel fragSim:
    simulation of ancient DNA fragments being retrieved at random from 
    the genome.
    """
    input:
        IN_FILE,
    output:
        OUTDIR_SIM + "gen_n{n}_l{l}.fa",
    benchmark:
        OUTDIR_BEN + "simulate_fragments/gen_n{n}_l{l}.tsv"
    wildcard_constraints:
        n="\d+",
        l="\d+",
    shell:
        "{FRAGSIM} -n {wildcards.n} -l {wildcards.l} {input} > {output}"


rule add_adapters:
    """
    gargammel adptSim:
    adding of adapters to create raw Illumina reads (without errors and
    quality scores)

    Output reads as ART (unzipped fasta) with wrap-around for paired-end
    mode.
    """
    input:
        OUTDIR_SIM + "gen_n{n}_l{l}.fa",
    output:
        OUTDIR_SIM + "gen_n{n}_l{l}_adpt.fa",
    benchmark:
        OUTDIR_BEN + "add_adapters/gen_n{n}_l{l}_adpt.tsv"
    wildcard_constraints:
        n="\d+",
        l="\d+",
    shell:
        # -l        : Desired read length
        # -artp     : Output reads as ART with wrap-around
        (
            "{ADPTSIM}" 
            " -l 125" 
            " -artp" 
            " {output}"
            " {input}"
        )


rule simulate_reads:
    """
    add sequencing errors and corresponding quality scores
    """
    input:
        OUTDIR_SIM + "gen_n{n}_l{l}_adpt.fa",
    output:
        OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    params:
        out_prefix=OUTDIR_SIM + "gen_n{n}_l{l}_s",
    benchmark:
        OUTDIR_BEN + "simulate_reads/gen_n{n}_l{l}_reads.tsv"
    wildcard_constraints:
        n="\d+",
        l="\d+",
    run:
        # --insRate     : insertion rate
        # -dr           : deletion rate
        # --seqSys      : HS25: Illumina HiSeq 2500 (125bp, 150bp)
        # --len         : read length
        # --rcount      : number of read pairs to be generated per sequence
        # --paired      : paired-end read simulation
        # --amplicon    : amplicon sequencing simulation
        # --noALN       : do not output ALN alignment file
        # --quiet       : turn off end of run summary
        # --rndSeed     : the seed for random number generator, use a
        #                 fixed seed to generate two identical datasets
        #                 from different runs
        shell(
            "{ART}"
            " --insRate 0 --insRate2 0"
            " -dr 0 -dr2 0"
            " --seqSys HS25"
            " --len 125"
            " --rcount 1"
            " --paired"
            " --amplicon"
            " --noALN"
            " --quiet"
            " --rndSeed {SEED}"
            " -i {input} -o {params.out_prefix}"
        )


### Reconstruction


rule leeHom:
    """Reconstruction using leeHom"""
    input:
        s1=OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        s2=OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    output:
        OUTDIR_REC + "leeHom/gen_n{n}_l{l}_lh.fq.gz",
    wildcard_constraints:
        n="\d+",
        l="\d+",
    params:
        out_prefix=OUTDIR_REC + "leeHom/gen_n{n}_l{l}_lh",
        rm1=OUTDIR_REC + "leeHom/gen_n{n}_l{l}_lh_r1.fq.gz",
        rm2=OUTDIR_REC + "leeHom/gen_n{n}_l{l}_lh_r2.fq.gz",
        rm3=OUTDIR_REC + "leeHom/gen_n{n}_l{l}_lh.fail.fq.gz",
        rm4=OUTDIR_REC + "leeHom/gen_n{n}_l{l}_lh_r1.fail.fq.gz",
        rm5=OUTDIR_REC + "leeHom/gen_n{n}_l{l}_lh_r2.fail.fq.gz",
    benchmark:
        OUTDIR_BEN + "leeHom/gen_n{n}_l{l}_lh.tsv"
    run:
        # (default : PHRED33)
        # -t [threads]            Use multiple cores (default : 1)
        shell(
            "{LEEHOM}"
            " --adapterFirstRead {ADPT1}"
            " --adapterSecondRead {ADPT2}"
            " --ancientdna"
            " -fq1 {input.s1}"
            " -fq2 {input.s2}"
            " -fqo {params.out_prefix}"
        )
        shell(
            "rm"
            " {params.rm1}"
            " {params.rm2}"
            " {params.rm3}"
            " {params.rm4}"
            " {params.rm5}"
        )


rule AdapterRemoval:
    """Reconstruction using AdapterRemoval"""
    input:
        s1=OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        s2=OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    output:
        OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar.collapsed",
    wildcard_constraints:
        n="\d+",
        l="\d+",
    params:
        out_prefix=OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar",
        rm1=OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar.pair1.truncated",
        rm2=OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar.pair2.truncated",
        rm3=OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar.singleton.truncated",
        rm4=OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar.discarded",
        rm5=OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar.collapsed.truncated",
        rm6=OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar.settings",
    benchmark:
        OUTDIR_BEN + "AdapterRemoval/gen_n{n}_l{l}_ar.tsv"
    run:
        # --seed SEED
        #   Sets the RNG seed used when choosing between bases with 
        #   equal Phred scores.
        # number of threads is by default 1
        shell(
            "{ADPTREM}"
            " --collapse"
            " --minlength 1"
            " --adapter1 {ADPT1}"
            " --adapter2 {ADPT2}"
            " --file1 {input.s1}"
            " --file2 {input.s2}"
            " --basename {params.out_prefix}"
            " --seed {SEED}"
        )
        shell(
            "rm"
            " {params.rm1}"
            " {params.rm2}"
            " {params.rm3}"
            " {params.rm4}"
            " {params.rm5}"
            " {params.rm6}"
        )
        

rule ClipAndMerge:
    """Reconstruction using ClipAndMerge"""
    input:
        s1=OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        s2=OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    output:
        OUTDIR_REC + "ClipAndMerge/gen_n{n}_l{l}_cm.fq",
    wildcard_constraints:
        n="\d+",
        l="\d+",
    benchmark:
        OUTDIR_BEN + "ClipAndMerge/gen_n{n}_l{l}_cm.tsv"
    shell:
        # Phred Score offset default: 33
        # -u FORWARD_FILE REVERSE_FILE  : Write unmerged forward and 
        #                   reverse reads to extra files. the regular
        #                   output file then only contains merged reads!
        (
            "java -jar {CLIPMERGE}"
            " -in1 {input.s1}"
            " -in2 {input.s2}"
            " -f {ADPT1}"
            " -r {ADPT2}"
            " -o {output}"
            " -l 1"
            #" -rm_no_partner"
        )


rule seqtk_adna_trim:
    """Reconstruction using seqtk and adna-trim"""
    input:
        s1=OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        s2=OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    output:
        OUTDIR_REC + "seqtk_adna_trim/gen_n{n}_l{l}_at.fq",
    wildcard_constraints:
        n="\d+",
        l="\d+",
    benchmark:
        OUTDIR_BEN + "seqtk_adna_trim/gen_n{n}_l{l}_at.tsv"
    shell:
        # seqtk mergepe: interleave two paired-end FASTA/Q files
        # adna-trim:
        # -l INT       min read/fragment length to output [default: 30]
        # -t INT       number of threads [default: 2]
        # -p STR       output PE reads to STR.R[12].fq.gz [default: discard pe]
        (
            "{SEQTK} mergepe"
            " {input.s1}"
            " {input.s2} |"
            " {ADNA}"
            " -l 1"
            " -t 1"
            " -"
            " > {output}"
        )


rule bbmerge:
    """Reconstruction using BBMerge"""
    input:
        s1=OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        s2=OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    output:
        m=OUTDIR_REC + "bbmerge/gen_n{n}_l{l}_bb.fq",
        #u1=OUTDIR_REC + "bbmerge/gen_n{n}_l{l}_bb.R1.fq",
        #u2=OUTDIR_REC + "bbmerge/gen_n{n}_l{l}_bb.R2.fq",
    wildcard_constraints:
        n="\d+",
        l="\d+",
    benchmark:
        OUTDIR_BEN + "bbmerge/gen_n{n}_l{l}_bb.tsv"
    shell:
        # t=1           : Set threads to 1
        # outu=<file>   : File for unmerged reads.
        (
            "{BBMERGE}"
            " in1={input.s1}"
            " in2={input.s2}"
            " out={output.m}"
            # " outu1={output.u1}"
            # " outu2={output.u2}"
            " adapter={ADPT_FILE}"
            " t=1"
            " mininsert=1"
            " mininsert0=1"
        )


rule fastp:
    """Reconstruction using fastp"""
    input:
        s1=OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        s2=OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    output:
        m=OUTDIR_REC + "fastp/gen_n{n}_l{l}_fp.fq",
        #u1=OUTDIR_REC + "fastp/gen_n{n}_l{l}_fp.R1.fq",
        #u2=OUTDIR_REC + "fastp/gen_n{n}_l{l}_fp.R2.fq",
        #json=OUTDIR_REC + "fastp/gen_n{n}_l{l}_fp_report.json",
        #html=OUTDIR_REC + "fastp/gen_n{n}_l{l}_fp_report.html",
    wildcard_constraints:
        n="\d+",
        l="\d+",
    benchmark:
        OUTDIR_BEN + "fastp/gen_n{n}_l{l}_fp.tsv"
    shell:
        # takes phread33 as input
        (
            "{FASTP}"
            " --merge "
            " --in1 {input.s1}"
            " --in2 {input.s2}"
            " --adapter_sequence {ADPT1}"
            " --adapter_sequence_r2 {ADPT2}"
            " --merged_out {output.m}"
            " --disable_length_filtering"
            " --length_required 1"
            # " --out1 {output.u1}"
            # " --out2 {output.u2}"
            " --json /dev/null"
            " --html /dev/null"
        )


rule SeqPrep:
    """Reconstruction using SeqPrep"""
    input:
        s1=OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        s2=OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    output:
        m=OUTDIR_REC + "SeqPrep/gen_n{n}_l{l}_sp.fq.gz",
        #u1=OUTDIR_REC + "SeqPrep/gen_n{n}_l{l}_sp.R1fq.gz",
        #u2=OUTDIR_REC + "SeqPrep/gen_n{n}_l{l}_sp.R2fq.gz",
    wildcard_constraints:
        n="\d+",
        l="\d+",
    benchmark:
        OUTDIR_BEN + "SeqPrep/gen_n{n}_l{l}_sp.tsv"
    shell:
        # The output is always gziped compressed.
        # -f <first read input fastq filename>
        # -r <second read input fastq filename>
        # -s <perform merging and output the merged reads to this file>
        # -1 <first read output fastq filename>
        # -2 <second read output fastq filename>
        # -L <Minimum length of a trimmed/merged read; default = 30>
        # -A <forward read primer/adapter sequence to trim>
        # -B <reverse read primer/adapter sequence to trim>
        (
            "{SEQPREP}"
            " -f {input.s1}"
            " -r {input.s2}"
            " -s {output.m}"
            " -1 /dev/null"
            " -2 /dev/null"
            " -L 1"
            " -A {ADPT1}"
            " -B {ADPT2}"
        )


### Evaluate trimming performance


rule evaluate:
    "Run the evaluation script and zip all fasta and fastq files"
    input:
        orig=OUTDIR_SIM + "gen_n{n}_l{l}.fa",
        lh=OUTDIR_REC + "leeHom/gen_n{n}_l{l}_lh.fq.gz",
        ar=OUTDIR_REC + "AdapterRemoval/gen_n{n}_l{l}_ar.collapsed",
        cm=OUTDIR_REC + "ClipAndMerge/gen_n{n}_l{l}_cm.fq",
        at=OUTDIR_REC + "seqtk_adna_trim/gen_n{n}_l{l}_at.fq",
        bb=OUTDIR_REC + "bbmerge/gen_n{n}_l{l}_bb.fq",
        fp=OUTDIR_REC + "fastp/gen_n{n}_l{l}_fp.fq",
        sp=OUTDIR_REC + "SeqPrep/gen_n{n}_l{l}_sp.fq.gz",
    output:
        lh_out=OUTDIR_EVA + "leeHom/gen_n{n}_l{l}_lh.csv",
        ar_out=OUTDIR_EVA + "AdapterRemoval/gen_n{n}_l{l}_ar.csv",
        cm_out=OUTDIR_EVA + "ClipAndMerge/gen_n{n}_l{l}_cm.csv",
        at_out=OUTDIR_EVA + "seqtk_adna_trim/gen_n{n}_l{l}_at.csv",
        bb_out=OUTDIR_EVA + "bbmerge/gen_n{n}_l{l}_bb.csv",
        fp_out=OUTDIR_EVA + "fastp/gen_n{n}_l{l}_fp.csv",
        sp_out=OUTDIR_EVA + "SeqPrep/gen_n{n}_l{l}_sp.csv",
    params:
        sim_r1=OUTDIR_SIM + "gen_n{n}_l{l}_s1.fq",
        sim_r2=OUTDIR_SIM + "gen_n{n}_l{l}_s2.fq",
    wildcard_constraints:
        n="\d+",
        l="\d+",
    conda:
        CONDA_ENV
    run:
        shell("gzip {params.sim_r1}")
        shell("gzip {params.sim_r2}")

        shell(
            "python3 {EVAL_SCRIPT}"
            " --out {output.lh_out}"
            " --nfrags {wildcards.n}"
            " --fraglen {wildcards.l}"
            " --tool leeHom"
            " --templates {input.orig}"
            " --reads {input.lh}"
        )

        shell(
            "python3 {EVAL_SCRIPT}"
            " --out {output.ar_out}"
            " --nfrags {wildcards.n}"
            " --fraglen {wildcards.l}"
            " --tool AdapterRemoval"
            " --templates {input.orig}"
            " --reads {input.ar}"
        )
        shell("gzip {input.ar}")

        shell(
            "python3 {EVAL_SCRIPT}"
            " --out {output.cm_out}"
            " --nfrags {wildcards.n}"
            " --fraglen {wildcards.l}"
            " --tool ClipAndMerge"
            " --templates {input.orig}"
            " --reads {input.cm}"
        )
        shell("gzip {input.cm}")

        shell(
            "python3 {EVAL_SCRIPT}"
            " --out {output.at_out}"
            " --nfrags {wildcards.n}"
            " --fraglen {wildcards.l}"
            " --tool seqtk_adna_trim"
            " --templates {input.orig}"
            " --reads {input.at}"
        )
        shell("gzip {input.at}")

        shell(
            "python3 {EVAL_SCRIPT}"
            " --out {output.bb_out}"
            " --nfrags {wildcards.n}"
            " --fraglen {wildcards.l}"
            " --tool bbmerge"
            " --templates {input.orig}"
            " --reads {input.bb}"
        )
        shell("gzip {input.bb}")

        shell(
            "python3 {EVAL_SCRIPT}"
            " --out {output.fp_out}"
            " --nfrags {wildcards.n}"
            " --fraglen {wildcards.l}"
            " --tool fastp"
            " --templates {input.orig}"
            " --reads {input.fp}"
        )
        shell("gzip {input.fp}")

        shell(
            "python3 {EVAL_SCRIPT}"
            " --out {output.sp_out}"
            " --nfrags {wildcards.n}"
            " --fraglen {wildcards.l}"
            " --tool SeqPrep"
            " --templates {input.orig}"
            " --reads {input.sp}"
        )

        shell("gzip {input.orig}")
