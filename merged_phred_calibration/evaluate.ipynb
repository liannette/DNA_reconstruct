{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_dict(merge_info_path, tool_name):\n",
    "    merge_dict = dict()\n",
    "    df = pd.read_csv(merge_info_path)\n",
    "    df = df[df[\"program\"] == tool_name].reset_index()\n",
    "    for index, row in df.iterrows():\n",
    "        key = (row[\"type\"], row[\"qs1\"], row[\"qs2\"])\n",
    "        merge_dict[key] = (int(row[\"new_nt\"][1]), row[\"new_qs\"])\n",
    "    return merge_dict\n",
    "\n",
    "\n",
    "def _next_fastq_entry(fastq_file, fraglen):\n",
    "    entry = dict()\n",
    "    entry[\"name\"] = fastq_file.readline().rstrip()[1:-4]\n",
    "    entry[\"sequence\"] = fastq_file.readline().rstrip()[:fraglen]\n",
    "    entry[\"optional\"] = fastq_file.readline().rstrip()\n",
    "    entry[\"quality\"] = fastq_file.readline().rstrip()[:fraglen]\n",
    "    return entry\n",
    "\n",
    "\n",
    "def _next_fasta_entry(fasta_file):\n",
    "    entry = dict()\n",
    "    entry[\"name\"] = fasta_file.readline().rstrip()[1:]\n",
    "    entry[\"sequence\"] = fasta_file.readline().rstrip()\n",
    "    return entry\n",
    "\n",
    "\n",
    "def get_next_entries(fragments_file, s1_file, s2_file, fraglen, dna_complement):\n",
    "    \"\"\"\n",
    "    Returns the next fasta entry of the file with the original \n",
    "    fragments, and the next fastq entries of the simulated reads. For \n",
    "    the mate2 read, the reverse complement sequence and the reverse \n",
    "    quality score line will be returned. Furthermore, the function will \n",
    "    raise an Assertion error, if the names of all sequences don't align.\n",
    "    \"\"\"\n",
    "    orig = _next_fasta_entry(fragments_file)\n",
    "    read1 = _next_fastq_entry(s1_file, fraglen)\n",
    "    read2 = _next_fastq_entry(s2_file, fraglen)\n",
    "    read2[\"sequence\"] = read2[\"sequence\"].translate(dna_complement)[::-1]\n",
    "    read2[\"quality\"] = read2[\"quality\"][::-1]\n",
    "    assert orig[\"name\"] == read1[\"name\"]\n",
    "    assert orig[\"name\"] == read2[\"name\"]\n",
    "    return orig, read1, read2\n",
    "\n",
    "\n",
    "def merged_base_and_qual(merge_dict, base1, base2, qual1, qual2):\n",
    "    # find out if the base matches in read1 and read2\n",
    "    if base1 == base2:\n",
    "        match_type = \"match\"\n",
    "    else:\n",
    "        match_type = \"mismatch\"\n",
    "    # get the merged base and quality score\n",
    "    new_nt, merged_qual = merge_dict[(match_type, qual1, qual2)]\n",
    "    merged_base = (base1, base2)[new_nt-1]\n",
    "    return merged_base, merged_qual\n",
    "\n",
    "\n",
    "def add_to_phred_counter(phred_counter, merged_qual, merged_base, orig_base):\n",
    "    # add to total count\n",
    "    try:\n",
    "        phred_counter[merged_qual][\"total_cnt\"] += 1\n",
    "    except KeyError:\n",
    "        # phred score not in dict, create key/value pair\n",
    "        phred_counter[merged_qual] = {\n",
    "            \"total_cnt\": 1, \n",
    "            \"error_cnt\": 0\n",
    "            }\n",
    "    # add to counter\n",
    "    if merged_base != orig_base:\n",
    "        phred_counter[merged_qual][\"error_cnt\"] += 1\n",
    "\n",
    "\n",
    "def process_reads(orig, read1, read2, merge_dict, phred_counter):\n",
    "    for pos in range(len(orig[\"sequence\"])):\n",
    "        # get merged base and quality\n",
    "        merged_base, merged_qual = merged_base_and_qual(\n",
    "            merge_dict, \n",
    "            read1[\"sequence\"][pos], \n",
    "            read2[\"sequence\"][pos], \n",
    "            read1[\"quality\"][pos] - 33, \n",
    "            read2[\"quality\"][pos] - 33,\n",
    "            )\n",
    "        # add count for the quality score\n",
    "        add_to_phred_counter(\n",
    "            phred_counter,\n",
    "            merged_qual,\n",
    "            merged_base,\n",
    "            orig[\"sequence\"][pos]\n",
    "            )\n",
    "\n",
    "\n",
    "def phred_2_p_error(q_value):\n",
    "    p_error = 10**(-int(q_value)/10)\n",
    "    return p_error\n",
    "\n",
    "\n",
    "def p_mismatch(n_total, n_mismatch):\n",
    "    if n_total == 0:\n",
    "        p = np.NAN\n",
    "    else:\n",
    "        p = n_mismatch/n_total\n",
    "    return p\n",
    "\n",
    "\n",
    "def binomial_ci(n, k, alpha):\n",
    "    \"\"\" \n",
    "    Exact Confidence Interval\n",
    "    https://sigmazone.com/binomial-confidence-intervals/ \n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        p_lower = 0\n",
    "    else: \n",
    "        p_lower = 1 - st.beta.ppf(1-(alpha/2), n-k+1 , k)\n",
    "    if k == n:\n",
    "        p_upper = 1\n",
    "    else:\n",
    "        p_upper = 1 - st.beta.ppf(alpha/2, n-k , k+1)\n",
    "    return p_lower, p_upper\n",
    "\n",
    "\n",
    "def p_error_2_phred(p_err, max_phred=100):\n",
    "    # probability of incorrect base call\n",
    "    if p_err <= 0:\n",
    "        phred_observed = max_phred\n",
    "    elif p_err == 1:\n",
    "        phred_observed = 0\n",
    "    else: \n",
    "        phred_observed = -10 * math.log10(p_err)\n",
    "    return phred_observed\n",
    "\n",
    "\n",
    "def get_results(phred_counter, alpha):\n",
    "    # set a maximum value for the observed phred, this is needed if the\n",
    "    # observed error rate is 0\n",
    "    max_phred = 100\n",
    "    \n",
    "    results = {'predicted_phred': list(),\n",
    "        'predicted_error': list(),\n",
    "        'n_matches': list(),\n",
    "        'n_mismatches': list(),\n",
    "        'n_total': list(),\n",
    "        'p_mismatch': list(),\n",
    "        'p_mismatch_lower': list(),\n",
    "        'p_mismatch_upper': list(),\n",
    "        'observed_phred': list(),\n",
    "        'observed_phred_lower': list(),\n",
    "        'observed_phred_upper': list(),\n",
    "        }\n",
    "    \n",
    "    for q_score in sorted(phred_counter.keys()):\n",
    "        \n",
    "        predicted_error = phred_2_p_error(q_score)\n",
    "        n_matches = phred_counter[q_score][\"match_cnt\"]\n",
    "        n_mismatches = phred_counter[q_score][\"mismatch_cnt\"]\n",
    "        n_total = n_mismatches + n_matches\n",
    "        p_mm = p_mismatch(n_total, n_mismatches)\n",
    "        p_mm_lower, p_mm_upper = binomial_ci(n_total, n_mismatches, alpha)\n",
    "        observed_phred = p_error_2_phred(p_mm, max_phred)\n",
    "        observed_phred_lower = p_error_2_phred(p_mm_upper, max_phred)\n",
    "        observed_phred_upper = p_error_2_phred(p_mm_lower, max_phred)\n",
    "    \n",
    "        results[\"predicted_phred\"].append(q_score)\n",
    "        results[\"predicted_error\"].append(predicted_error)\n",
    "        results[\"n_matches\"].append(n_matches)\n",
    "        results[\"n_mismatches\"].append(n_mismatches)\n",
    "        results[\"n_total\"].append(n_total)\n",
    "        results[\"p_mismatch\"].append(p_mm)\n",
    "        results[\"p_mismatch_lower\"].append(p_mm_lower)\n",
    "        results[\"p_mismatch_upper\"].append(p_mm_upper)\n",
    "        results[\"observed_phred\"].append(observed_phred)\n",
    "        results[\"observed_phred_lower\"].append(observed_phred_lower)\n",
    "        results[\"observed_phred_upper\"].append(observed_phred_upper)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def main(template_path, s1_path, s2_path, merge_info_path, nfrags, fraglen, qualityshift, tool_name,\n",
    "         export_path=None):\n",
    "\n",
    "    alpha = 0.01\n",
    "\n",
    "    # Load files\n",
    "    templates_file = gzip.open(template_path, \"rb\") if common._is_gzipped(template_path) else open(template_path, \"rb\")\n",
    "    s1_file = gzip.open(s1_path, \"rb\") if common._is_gzipped(s1_path) else open(s1_path, \"rb\")\n",
    "    s2_file = gzip.open(s2_path, \"rb\") if common._is_gzipped(s2_path) else open(s2_path, \"rb\")\n",
    "    merge_dict = get_merge_dict(merge_info_path, tool_name)\n",
    "\n",
    "    # Analysis\n",
    "    phred_counter = dict()\n",
    "    dna_complement = bytes.maketrans(b\"ACTG\", b\"TGAC\")\n",
    "    for _ in range(nfrags):\n",
    "        orig, read1, read2 = get_next_entries(templates_file, s1_file, s2_file, fraglen, dna_complement)\n",
    "        process_reads(orig, read1, read2, merge_dict, phred_counter)\n",
    "    \n",
    "    results = get_results(phred_counter, alpha)\n",
    "\n",
    "\n",
    "    # Export results \n",
    "    if export_path is not None:\n",
    "        df = pd.DataFrame.from_dict(results)\n",
    "        df.insert(0, 'program', tool_name)\n",
    "        df.insert(1, 'nfrags', nfrags)\n",
    "        df.insert(2, 'fraglen', fraglen)\n",
    "        df.insert(3, 'qual_shift', qualityshift)\n",
    "        df.insert(4, 'alpha', alpha)\n",
    "        df.to_csv(export_path, na_rep=\"NA\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_path = os.path.join(\"output\", \"simulations\", \"gen_n1000000_l120_frag.fa\")\n",
    "s1_path = os.path.join(\"output\", \"simulations\", \"gen_n1000000_l120_s1.fq\")\n",
    "s2_path = os.path.join(\"output\", \"simulations\", \"gen_n1000000_l120_s2.fq\")\n",
    "merge_info_path = \"input/all_qs.csv\"\n",
    "tool_name = \"fastp\"\n",
    "fraglen = 120\n",
    "nfrags = 1000000\n",
    "alpha = 0.01\n",
    "export_path = None\n",
    "qualityshift = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "templates_file = gzip.open(template_path, \"rb\") if common._is_gzipped(template_path) else open(template_path, \"rb\")\n",
    "s1_file = gzip.open(s1_path, \"rb\") if common._is_gzipped(s1_path) else open(s1_path, \"rb\")\n",
    "s2_file = gzip.open(s2_path, \"rb\") if common._is_gzipped(s2_path) else open(s2_path, \"rb\")\n",
    "merge_dict = get_merge_dict(merge_info_path, tool_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "phred_counter2 = dict()\n",
    "dna_complement = bytes.maketrans(b\"ACTG\", b\"TGAC\")\n",
    "for _ in range(nfrags):\n",
    "    orig, read1, read2 = get_next_entries(templates_file, s1_file, s2_file, fraglen, dna_complement)\n",
    "    break \n",
    "\n",
    "for pos in range(len(orig[\"sequence\"])):\n",
    "    orig_base = orig[\"sequence\"][pos]\n",
    "    base1 = read1[\"sequence\"][pos]\n",
    "    base2 = read2[\"sequence\"][pos]\n",
    "    # get the quality score of read1 and read2\n",
    "    qual1 = read1[\"quality\"][pos] - 33\n",
    "    qual2 = read2[\"quality\"][pos] - 33\n",
    "\n",
    "    merged_base, merged_qual = merged_base_and_qual(merge_dict, \n",
    "                                                        base1, base2, \n",
    "                                                        qual1, qual2)\n",
    "    # add count for the quality score\n",
    "    add_to_phred_counter(phred_counter2, merged_qual, merged_base, orig_base)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: {'total_cnt': 1, 'error_cnt': 0}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phred_counter = dict()\n",
    "phred_counter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_singlethread_counter(phred_counter_list, phred_counter):\n",
    "    for phred_counter_st in phred_counter_list:\n",
    "        for phred in phred_counter_st.keys():\n",
    "            try:\n",
    "                phred_counter[phred][\"total_cnt\"] \\\n",
    "                    += phred_counter_st[phred][\"total_cnt\"]\n",
    "                phred_counter[phred][\"error_cnt\"] \\\n",
    "                    += phred_counter_st[phred][\"error_cnt\"]\n",
    "            except KeyError:\n",
    "                phred_counter[phred] = phred_counter_st[phred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: {'total_cnt': 2, 'error_cnt': 0}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_singlethread_counter([phred_counter2], phred_counter)\n",
    "phred_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('DNA_reconstruct')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8459558287d1226675af77e66f79fd99046c580ac7351312d202b93a96e3ee12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
